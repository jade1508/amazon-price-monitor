name: Daily Price Check

on:
  schedule:
    - cron: '0 7 * * *'   # Every day at 7 AM UTC
  workflow_dispatch:      # Allows manual run

jobs:
  scrape-and-upload:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Install system dependencies for Playwright
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            ca-certificates fonts-liberation libasound2t64 libatk-bridge2.0-0 \
            libatk1.0-0 libatspi2.0-0 libdrm2 libgtk-3-0 libnspr4 libnss3 \
            libx11-xcb1 libxcomposite1 libxdamage1 libxext6 libxfixes3 libxrandr2 \
            libgbm1 libxkbcommon0 libpango-1.0-0 libcairo2 libgdk-pixbuf-2.0-0 \
            xvfb

      - name: Install Playwright browsers
        run: playwright install chromium --with-deps

      - name: Run Amazon scraper
        run: python scraper.py

      - name: Verify CSV was created
        run: |
          if [ ! -f "output/latest_prices.csv" ]; then
            echo "CSV not generated!"
            exit 1
          fi
          echo "CSV created with $(wc -l < output/latest_prices.csv) lines"

      - name: Upload to Databricks Volume (OFFICIAL METHOD — WORKS 100%)
        env:
          DATABRICKS_HOST: ${{ secrets.DB_HOST }}      
          DATABRICKS_TOKEN: ${{ secrets.DB_TOKEN }}   
        run: |
          echo "Installing Databricks CLI..."
          pip install --quiet --upgrade databricks-cli

          echo "Creating config file..."
          mkdir -p ~/.databrickscfg
          rm -rf ~/.databrickscfg                   
          cat > ~/.databrickscfg << EOF
          [DEFAULT]
          host = $DATABRICKS_HOST
          token = $DATABRICKS_TOKEN
          EOF

          echo "Uploading latest_prices.csv to Databricks volume..."
          databricks fs cp --overwrite \
            output/latest_prices.csv \
            dbfs:/Volumes/jade_catalog/price_schema/price_volume/latest_prices.csv

          echo "UPLOAD SUCCESSFUL — file is now in your Databricks volume!"
